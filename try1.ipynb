{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel('dataset.xlsx')\n",
    "df['KOSTENRUBRIEK - declared'] = df['KOSTENRUBRIEK - declared'].str.lower()\n",
    "df['FLC: REDEN VERWERPING'] = df['FLC: REDEN VERWERPING'].str.lower()\n",
    "df['BESCHRIJVING DECLARATIE'] = df['BESCHRIJVING DECLARATIE'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Flags:\n",
      "the cost was declared in the wrong category\n",
      "double declaration\n",
      "please specify the correct invoiced amount\n",
      "costs that are declared too late, can only be reimbursed for 50%\n",
      "purchase not eligible for subsidy\n",
      "please specify the correct supplier\n"
     ]
    }
   ],
   "source": [
    "# Extract unique flags from the \"FLC: REDEN VERWERPING\" column\n",
    "all_flags = df[\"FLC: REDEN VERWERPING\"].str.split('|', expand=True).stack().str.strip().unique()\n",
    "\n",
    "# Print the unique flags\n",
    "print(\"Unique Flags:\")\n",
    "for flag in all_flags:\n",
    "    print(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the phrases to check for in the specified column\n",
    "phrases = {\n",
    "    \"FLC: REDEN VERWERPING\": {\n",
    "        \"double declaration\": \"double\",\n",
    "        \"too late\": \"late\",\n",
    "        \"correct invoiced amount\": \"amount\",\n",
    "        \"supplier\": \"supplier\",\n",
    "        \"wrong category\": \"category\",\n",
    "        \"eligible\": \"eligible\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Iterate through the phrases and update the corresponding columns\n",
    "for column_name, conditions in phrases.items():\n",
    "    for phrase, new_column in conditions.items():\n",
    "        df[new_column] = df[column_name].str.contains(phrase, case=False, na=False).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"DATUM FACTUUR - DECLARED\" column to datetime format\n",
    "df['DATUM FACTUUR - DECLARED'] = pd.to_datetime(df['DATUM FACTUUR - DECLARED'], errors='coerce')\n",
    "\n",
    "# Create the \"latest\" column by moving the month 6 months forward\n",
    "df['latest'] = df['DATUM FACTUUR - DECLARED'] + pd.DateOffset(months=6)\n",
    "\n",
    "# Convert date columns to datetime objects\n",
    "df['latest'] = pd.to_datetime(df['latest'])\n",
    "df['DECLARATIEDATUM (can be assumed to be close to payment date)'] = pd.to_datetime(df['DECLARATIEDATUM (can be assumed to be close to payment date)'])\n",
    "\n",
    "# Calculate the time difference and create a new column 'timediff'\n",
    "df['pred.late'] = (df['DECLARATIEDATUM (can be assumed to be close to payment date)'] - df['latest']).dt.days > 0\n",
    "df['pred.late'] = df['pred.late'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong amount (only EUR works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred.amount'] = (df['BETAALD BEDRAG - extracted from invoice'] - df['BETAALD BEDRAG - declared ']).apply(lambda x: 1 if x < 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong supplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred.supplier'] = (df['LEVERANCIER - EXTRACTED'] != df['LEVERANCIER - DECLARED']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred.date'] = (df['DATUM FACTUUR - extracted'] != df['DATUM FACTUUR - DECLARED']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "\n",
      "Classification Report:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                  equipment       0.95      0.95      0.95        19\n",
      "          external services       0.87      0.91      0.89        22\n",
      "infrastructure and building       0.94      0.94      0.94        16\n",
      "          preparation costs       0.90      0.82      0.86        22\n",
      "               travel costs       0.94      1.00      0.97        16\n",
      "\n",
      "                   accuracy                           0.92        95\n",
      "                  macro avg       0.92      0.92      0.92        95\n",
      "               weighted avg       0.92      0.92      0.92        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where \"category\" column has value 0\n",
    "df2 = df[df['category'] == 0]\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "df2.to_csv('cat_data.csv', index=False)\n",
    "\n",
    "# Train model on positive targets\n",
    "X = df2['BESCHRIJVING DECLARATIE']\n",
    "y = df2['KOSTENRUBRIEK - declared']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Multinomial Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "classification_rep = classification_report(y_test, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "\n",
      "Classification Report:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                  equipment       0.00      0.00      0.00         8\n",
      "          external services       0.00      0.00      0.00         8\n",
      "infrastructure and building       0.00      0.00      0.00         3\n",
      "          preparation costs       0.25      0.50      0.33         2\n",
      "               travel costs       0.00      0.00      0.00         1\n",
      "\n",
      "                   accuracy                           0.05        22\n",
      "                  macro avg       0.05      0.10      0.07        22\n",
      "               weighted avg       0.02      0.05      0.03        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use model to predict on negative targets\n",
    "df_category_1 = df[df['category'] == 1]\n",
    "\n",
    "# Extract text data and labels\n",
    "X_category_1 = df_category_1['BESCHRIJVING DECLARATIE']\n",
    "y_category_1 = df_category_1['KOSTENRUBRIEK - declared']\n",
    "\n",
    "# Vectorize the text data using the same TF-IDF vectorizer\n",
    "X_category_1_tfidf = vectorizer.transform(X_category_1)\n",
    "\n",
    "# Make predictions on the instances where 'category' has value 1\n",
    "predictions_category_1 = classifier.predict(X_category_1_tfidf)\n",
    "\n",
    "# Evaluate the model on these instances\n",
    "accuracy_category_1 = accuracy_score(y_category_1, predictions_category_1)\n",
    "classification_rep_category_1 = classification_report(y_category_1, predictions_category_1)\n",
    "\n",
    "print(f'Accuracy: {1-accuracy_category_1:.2f}')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_rep_category_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=set(stopwords.words(\"english\"))\n",
    "df = pd.read_excel(\"eli_data.xlsx\")\n",
    "print(df[\"BESCHRIJVING DECLARATIE\"])\n",
    "\n",
    "\n",
    "def vectorize_text(text_data):\n",
    "    # Create a CountVectorizer\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    #taking out the stopwords from the descriptions\n",
    "    text_data = [preprocess_text(text) for text in text_data]\n",
    "\n",
    "    # Fit and transform the description\n",
    "    vectorized_data = vectorizer.fit_transform(text_data)\n",
    "\n",
    "    return vectorized_data, vectorizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    # Join the filtered words back into a string\n",
    "    processed_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "\n",
    "vectorized_data, vectorizer = vectorize_text(df[\"BESCHRIJVING DECLARATIE\"])\n",
    "#print(vectorized_data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_data, df[\"eligible\"], random_state=0)\n",
    "#print(X_train,y_train)\n",
    "clf = DecisionTreeClassifier(random_state=0,class_weight=\"balanced\")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.show()\n",
    "\n",
    "print(y_pred,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Excel file saved to: output_file.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save the updated DataFrame to a new Excel file\n",
    "output_file_path = 'output_file.xlsx'\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Updated Excel file saved to: {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holyhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
